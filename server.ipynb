{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "import nltk\n",
    "import gensim.downloader as api\n",
    "import numpy as np\n",
    "import timeit\n",
    "from itertools import groupby\n",
    "\n",
    "from pymilvus import Collection\n",
    "from pymilvus import connections\n",
    "from flask import Flask, render_template, request\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from joblib import load\n",
    "from statistics import mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init server variables...\n"
     ]
    }
   ],
   "source": [
    "print('Init server variables...')\n",
    "scaler = load('models/scaler.joblib')\n",
    "sentences_splitter = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "wl = WordNetLemmatizer()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init MilvusDB...\n"
     ]
    }
   ],
   "source": [
    "print('Init MilvusDB...')\n",
    "connections.connect(\n",
    "    alias=\"default\",\n",
    "    host='localhost',\n",
    "    port='19530'\n",
    ")\n",
    "collection = Collection('documents')\n",
    "collection.load()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model...\n",
      "Model loaded in 34.58765059999132 seconds!\n"
     ]
    }
   ],
   "source": [
    "print('Loading model...')\n",
    "start = timeit.default_timer()\n",
    "wv = api.load('word2vec-google-news-300')\n",
    "index2word_set = set(wv.index_to_key)\n",
    "stop = timeit.default_timer()\n",
    "print(f'Model loaded in {stop - start} seconds!')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "# Cleaning\n",
    "def cleaning(s):\n",
    "    # Lowercase text\n",
    "    s = s.lower()\n",
    "    # Trim text\n",
    "    s = s.strip()\n",
    "    # Remove punctuations, special characters, URLs & hashtags\n",
    "    s = re.compile('<.*?>').sub('', s)\n",
    "    s = re.compile('[%s]' % re.escape(string.punctuation)).sub(' ', s)\n",
    "    s = re.sub('\\s+', ' ', s)\n",
    "    s = re.sub(r'\\[[0-9]*\\]', ' ', s)\n",
    "    s = re.sub(r'[^\\w\\s]', '', str(s).lower().strip())\n",
    "    s = re.sub(r'\\d', ' ', s)\n",
    "    s = re.sub(r'\\s+', ' ', s)\n",
    "\n",
    "    return s\n",
    "\n",
    "\n",
    "# Remove stopword\n",
    "def stopword(s):\n",
    "    a = [i for i in s.split() if i not in stopwords.words('english')]\n",
    "    return ' '.join(a)\n",
    "\n",
    "\n",
    "# This is a helper function to map NTLK position tags\n",
    "def get_wordnet_pos(tag):\n",
    "    if tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN\n",
    "\n",
    "\n",
    "# Tokenize the sentence\n",
    "def lemmatizer(s):\n",
    "    word_pos_tags = nltk.pos_tag(word_tokenize(s))  # Get position tags\n",
    "    a = [wl.lemmatize(tag[0], get_wordnet_pos(tag[1])) for idx, tag in\n",
    "         enumerate(word_pos_tags)]  # Map the position tag and lemmatize the word/token\n",
    "    return \" \".join(a)\n",
    "\n",
    "\n",
    "# Preprocessing\n",
    "def preprocess(s):\n",
    "    s = cleaning(s)\n",
    "    s = stopword(s)\n",
    "    s = lemmatizer(s)\n",
    "    return s\n",
    "\n",
    "\n",
    "# Feature extraction\n",
    "def avg_feature_vector(sentence, model, num_features, index):\n",
    "    words = sentence.split()\n",
    "    feature_vec = np.zeros((num_features, ), dtype='float32')\n",
    "    n_words = 0\n",
    "    for word in words:\n",
    "        if word in index:\n",
    "            n_words += 1\n",
    "            feature_vec = np.add(feature_vec, model[word])\n",
    "    if n_words > 0:\n",
    "        feature_vec = np.divide(feature_vec, n_words)\n",
    "    return feature_vec\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ 1.81738064e-02, -5.25945686e-02,  5.41344695e-02,\n         2.36477982e-02, -7.01663718e-02,  2.99715064e-02,\n        -2.35252338e-03,  6.56126812e-02,  8.41437206e-02,\n        -3.24970931e-02, -2.57467590e-02, -5.67510650e-02,\n         7.94855319e-03,  4.59639393e-02,  5.71175814e-02,\n        -3.75173613e-02, -7.08127990e-02,  2.49954164e-02,\n        -1.97182372e-02, -1.25621453e-01,  1.01160118e-02,\n         1.36857545e-02, -3.66127342e-02,  6.53620511e-02,\n        -1.99537426e-02, -1.98749676e-02,  7.50762671e-02,\n         2.08483525e-02, -8.18253905e-02,  4.27742861e-02,\n         7.33862221e-02, -8.67684409e-02,  4.29857299e-02,\n         1.17880385e-02, -5.15621752e-02, -5.59849432e-03,\n         4.91640754e-02, -3.36822756e-02,  5.77653982e-02,\n        -6.21243753e-02,  8.22758377e-02,  6.57420531e-02,\n        -7.51300901e-02,  7.50541082e-03,  5.87132014e-02,\n        -7.31290728e-02, -1.92129798e-02, -1.73566933e-03,\n        -4.20353524e-02, -1.34568494e-02,  2.61305291e-02,\n        -6.36109337e-02, -1.13538526e-01, -3.87851447e-02,\n        -5.83104901e-02,  2.67645940e-02,  8.72388191e-04,\n        -4.22669202e-02,  9.07947794e-02, -2.56088451e-02,\n         4.52575013e-02,  3.73464003e-02,  5.01392148e-02,\n         1.22044031e-02, -4.22669016e-02,  9.61800367e-02,\n        -1.37573564e-02,  1.12849042e-01, -5.54784797e-02,\n        -9.60574299e-02,  2.38272035e-03, -4.27030735e-02,\n         7.50001520e-02,  2.42227502e-02,  4.51730751e-02,\n        -1.21653648e-02,  6.43193275e-02, -5.94896227e-02,\n         1.74797978e-02,  6.01220578e-02, -4.98257764e-02,\n         1.70211624e-02,  4.20540161e-02,  1.06168799e-02,\n         1.65312570e-02, -1.15250885e-01, -3.34527940e-02,\n         7.46905357e-02, -8.81286636e-02,  8.04940164e-02,\n         1.17580093e-01, -3.04049086e-02, -2.54958495e-02,\n         1.99538446e-03,  7.65194045e-03, -5.16567491e-02,\n         4.48955446e-02, -2.53878217e-02,  4.37503541e-03,\n         7.50897303e-02,  7.44326413e-02, -1.03067927e-01,\n        -3.83636877e-02, -2.96435561e-02, -2.35001463e-02,\n        -3.44753116e-02, -2.91899368e-02, -5.91197200e-02,\n         8.91325772e-02, -2.41626557e-02, -3.49981748e-02,\n         7.33096302e-02, -8.83997418e-03, -5.67158610e-02,\n        -1.15239993e-02,  9.45924781e-03,  2.49582548e-02,\n         1.92030855e-02,  6.75247759e-02,  7.01612383e-02,\n        -5.71519770e-02,  5.74468710e-02, -2.65285894e-02,\n         1.12010501e-02, -8.31222013e-02,  8.58499482e-02,\n         5.33639900e-02, -2.24749781e-02, -3.44110988e-02,\n         1.62757989e-02,  5.34261540e-02, -9.45162028e-02,\n        -3.30422521e-02,  9.38259065e-02,  3.13338079e-02,\n        -5.89682795e-02,  7.13528618e-02,  7.46068880e-02,\n        -4.03277855e-03,  4.16490762e-03,  6.02107011e-02,\n         5.13821356e-02, -4.60725911e-02,  3.70433517e-02,\n         1.92903727e-02, -4.98690009e-02,  7.78541863e-02,\n         1.74691081e-02,  4.49281232e-03, -8.72756764e-02,\n        -4.24874946e-02,  1.44476984e-02, -1.85359754e-02,\n        -1.03619264e-03, -2.30675023e-02,  6.36890009e-02,\n        -5.19508980e-02, -7.08985105e-02,  4.44710925e-02,\n         1.30124101e-02,  6.71163425e-02, -1.01158964e-02,\n        -4.14411761e-02,  4.35393266e-02, -2.19030697e-02,\n         6.46163225e-02, -3.73068452e-02,  5.20409364e-03,\n        -2.33902968e-03, -1.07035674e-01,  1.03732586e-01,\n         3.74445692e-02, -6.51516691e-02, -2.78020389e-02,\n         6.05918914e-02,  9.71309468e-03, -4.37310971e-02,\n        -2.30526254e-02, -6.11530617e-02,  4.57851663e-02,\n         1.46831935e-02,  4.52250615e-02,  5.28109632e-02,\n        -7.60442242e-02,  4.05899882e-02,  4.53520492e-02,\n        -3.13894711e-02,  2.29013935e-02, -7.37609118e-02,\n         2.10636854e-02, -1.22722633e-01, -1.76767372e-02,\n         1.05132312e-01, -7.79175088e-02,  1.65078267e-02,\n        -6.45250455e-02,  1.30496010e-01, -7.28748590e-02,\n        -4.42315191e-02, -2.81792562e-02, -2.37589441e-02,\n         2.38347668e-02,  9.81860422e-03, -7.00088777e-03,\n        -4.43766080e-02,  1.02543555e-01,  8.14087838e-02,\n        -8.75923187e-02,  1.29437476e-01,  1.10133216e-04,\n        -1.30590415e-02, -2.36228369e-02,  2.48264950e-02,\n         1.33373251e-03, -7.27697462e-03, -1.06259562e-01,\n         1.37601554e-01,  2.12185252e-02,  6.46445528e-02,\n         8.19701925e-02, -5.71428100e-03,  5.44939004e-02,\n        -1.84334163e-02, -1.13556750e-01,  1.16602719e-01,\n        -9.61401537e-02,  8.39098021e-02, -2.15536803e-02,\n        -6.65506050e-02,  3.87579948e-03,  1.14127874e-01,\n         9.20352191e-02, -5.03636189e-02,  1.55255981e-02,\n        -6.92696497e-02,  4.45415638e-02,  4.28885892e-02,\n        -1.16898073e-02,  1.43262565e-01,  4.74409759e-03,\n        -4.01516072e-02, -1.04743980e-01, -8.75154918e-04,\n         1.06478848e-01, -2.26206612e-02,  1.39924465e-02,\n        -1.59155242e-02, -7.26274587e-03,  6.42440701e-03,\n        -3.82633368e-03,  5.35726212e-02,  7.76517391e-02,\n        -1.31119668e-01, -7.16724992e-02, -6.29181564e-02,\n         7.29822963e-02, -3.02460473e-02,  2.78278496e-02,\n        -3.09904255e-02,  8.48916247e-02, -6.57716095e-02,\n        -4.06958237e-02, -2.98432689e-02, -1.93892512e-02,\n        -2.34553088e-02, -4.84953187e-02,  1.63708464e-03,\n        -7.79887475e-03,  1.50292953e-02, -2.79505216e-02,\n         8.57344940e-02,  1.13425165e-01,  2.39783991e-02,\n        -3.28189209e-02,  5.38545921e-02,  4.38181050e-02,\n         6.42803088e-02,  1.71014033e-02,  7.19536990e-02,\n         6.42655268e-02, -6.37820438e-02, -2.07165480e-02,\n         6.83623403e-02,  4.33949847e-03, -6.18714057e-02,\n         6.42070919e-03, -8.72052312e-02, -1.14382669e-01,\n         8.03326741e-02, -4.01401818e-02, -1.93176717e-02,\n         6.56146929e-02,  1.27453119e-01, -1.67014189e-02,\n         5.93292899e-02,  2.06269808e-02,  6.34326562e-02,\n         1.90991536e-02, -1.09957447e-02, -1.05206020e-01]], dtype=float32)"
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = load('models/scaler.joblib')\n",
    "texts = \"Predictive models allow subject-specific inference when analyzing disease\\nrelated alterations in neuroimaging data.\"\n",
    "texts = sentences_splitter.tokenize(texts)\n",
    "\n",
    "clean_texts = [preprocess(text) for text in texts]\n",
    "\n",
    "vectors = avg_feature_vector('predictive model allow subject specific inference analyze disease related alteration neuroimaging data', model=wv, num_features=300, index=index2word_set)\n",
    "vectors = np.array([vectors])\n",
    "vectors = scaler.transform(vectors)\n",
    "vectors = np.array([vector / np.linalg.norm(vector) for vector in vectors])\n",
    "vectors"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "data": {
      "text/plain": "['predictive model allow subject specific inference analyze disease related alteration neuroimaging data']"
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_texts"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "data": {
      "text/plain": "'[\"[\\'(distance: 1.0000001192092896, id: 435919503349404884)\\']\"]'"
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_result = collection.search(\n",
    "    data=vectors,\n",
    "    anns_field='vector',\n",
    "    param=dict(metric_type='IP', params=dict(nprobe=1)),\n",
    "    limit=1,\n",
    "    output_fields=['title', 'text', 'hash']\n",
    ")\n",
    "\n",
    "results = []\n",
    "reports = []\n",
    "score = 0\n",
    "for i, item in enumerate(query_result):\n",
    "    if len(item) > 0 and item[0].distance > 0.85:\n",
    "        results.append(item[0].id)\n",
    "        reports.append({\n",
    "            'index': i,\n",
    "            'id': item[0].id,\n",
    "            'title': item[0].entity.get('title'),\n",
    "            'text': item[0].entity.get('text'),\n",
    "            'hash': item[0].entity.get('hash'),\n",
    "            'distance': round(item[0].distance * 100, 1)\n",
    "        })\n",
    "        score += 1 - item[0].distance\n",
    "    else:\n",
    "        score += 1\n",
    "        results.append(None)\n",
    "\n",
    "reports = sorted(reports, key=lambda x: x['hash'])\n",
    "reports = [(key, list(group)) for key, group in groupby(reports, key=lambda x: x['hash'])]\n",
    "reports = sorted(reports, key=lambda x: mean([el['distance'] for el in x[1]]), reverse=True)\n",
    "score = 100 - round(score / len(vectors) * 100, 2)\n",
    "str(query_result)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}