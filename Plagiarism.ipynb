{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Imports"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 16 CPU Cores\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import re, string\n",
    "import multiprocessing\n",
    "import numpy as np\n",
    "import gensim.downloader as api\n",
    "\n",
    "from tqdm import tqdm\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from pymilvus import connections\n",
    "from pymilvus import CollectionSchema, FieldSchema, DataType\n",
    "from pymilvus import Collection\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from joblib import dump, load\n",
    "\n",
    "tqdm.pandas()\n",
    "cores = multiprocessing.cpu_count() # Count the number of cores in a computer\n",
    "\n",
    "print(f'Total {cores} CPU Cores')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load Dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "3YQTEDJ-4O3w"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "   id                                              title  \\\n0   1        Reconstructing Subject-Specific Effect Maps   \n1   2                 Rotation Invariance Neural Network   \n2   3  Spherical polyharmonics and Poisson kernels fo...   \n3   4  A finite element approximation for the stochas...   \n4   5  Comparative study of Discrete Wavelet Transfor...   \n\n                                            abstract  \n0    Predictive models allow subject-specific inf...  \n1    Rotation invariance and translation invarian...  \n2    We introduce and develop the notion of spher...  \n3    The stochastic Landau--Lifshitz--Gilbert (LL...  \n4    Fourier-transform infra-red (FTIR) spectra o...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>title</th>\n      <th>abstract</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>Reconstructing Subject-Specific Effect Maps</td>\n      <td>Predictive models allow subject-specific inf...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>Rotation Invariance Neural Network</td>\n      <td>Rotation invariance and translation invarian...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>Spherical polyharmonics and Poisson kernels fo...</td>\n      <td>We introduce and develop the notion of spher...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>A finite element approximation for the stochas...</td>\n      <td>The stochastic Landau--Lifshitz--Gilbert (LL...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>Comparative study of Discrete Wavelet Transfor...</td>\n      <td>Fourier-transform infra-red (FTIR) spectra o...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = ['ID', 'TITLE', 'ABSTRACT']\n",
    "\n",
    "# Read CSV\n",
    "df_train = pd.read_csv('inputs/train_tm/train.csv', delimiter=',', usecols=columns)\n",
    "df_test = pd.read_csv('inputs/test_tm/test.csv', delimiter=',', usecols=columns)\n",
    "\n",
    "# Rename columns to lower case\n",
    "df_train.columns = df_train.columns.str.lower()\n",
    "df_test.columns = df_test.columns.str.lower()\n",
    "\n",
    "df_train.head()"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "C6sStAlj4O3y",
    "outputId": "d80f574a-db65-4820-cb97-8109f818a315"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "df_train['abstract_word_count'] = df_train['abstract'].apply(lambda x: len(x.split()))\n",
    "df_train['abstract_word_count'].mean()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lBqiJmRWvEZq",
    "outputId": "76453248-428e-4fac-c03b-ac1d8ff84a0a",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "148.40487316421897"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "df_train['abstract_char_count'] = df_train['abstract'].apply(lambda x: len(str(x)))\n",
    "df_train['abstract_char_count'].mean()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zYHXUVfzvH2g",
    "outputId": "f821fd6a-47ea-4055-8c86-8796553c4e1b",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "1009.1033759298111"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "df_train[df_train['abstract'].duplicated()]"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49
    },
    "id": "bKTicYzAET6O",
    "outputId": "c2bbd62b-e560-4072-9273-6ebb6b4bf62e",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "Empty DataFrame\nColumns: [id, title, abstract, abstract_word_count, abstract_char_count]\nIndex: []",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>title</th>\n      <th>abstract</th>\n      <th>abstract_word_count</th>\n      <th>abstract_char_count</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "df_train[df_train['title'].duplicated()]"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49
    },
    "id": "bT1SIVajw2q4",
    "outputId": "6a1dfe26-48bf-40bb-c0ee-b31ffb07bff6",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "Empty DataFrame\nColumns: [id, title, abstract, abstract_word_count, abstract_char_count]\nIndex: []",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>title</th>\n      <th>abstract</th>\n      <th>abstract_word_count</th>\n      <th>abstract_char_count</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Preprocessing"
   ],
   "metadata": {
    "id": "feMR7HIoqJGV",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "print('nltk package is ready...')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I__Zz-PuqKjD",
    "outputId": "3be36e97-3c3b-4136-d7d7-5a554cd517a4",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nltk package is ready...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\myxzlpltk\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\myxzlpltk\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\myxzlpltk\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\myxzlpltk\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\myxzlpltk\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "sentences_splitter = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "\n",
    "df_train['text'] = df_train['abstract'].progress_apply(lambda x: sentences_splitter.tokenize(x))\n",
    "df_train = df_train.explode('text', ignore_index=True)\n",
    "df_train.head()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 641
    },
    "id": "gPOnWF7m0EO_",
    "outputId": "e0ad62c9-dd4c-4596-a801-e75dec7e1580",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 8,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20972/20972 [00:02<00:00, 10230.22it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": "   id                                        title  \\\n0   1  Reconstructing Subject-Specific Effect Maps   \n1   1  Reconstructing Subject-Specific Effect Maps   \n2   1  Reconstructing Subject-Specific Effect Maps   \n3   1  Reconstructing Subject-Specific Effect Maps   \n4   1  Reconstructing Subject-Specific Effect Maps   \n\n                                            abstract  abstract_word_count  \\\n0    Predictive models allow subject-specific inf...                  265   \n1    Predictive models allow subject-specific inf...                  265   \n2    Predictive models allow subject-specific inf...                  265   \n3    Predictive models allow subject-specific inf...                  265   \n4    Predictive models allow subject-specific inf...                  265   \n\n   abstract_char_count                                               text  \n0                 1912    Predictive models allow subject-specific inf...  \n1                 1912  Given a subject's data, inference can\\nbe made...  \n2                 1912  identifiying condition presence for the\\nsubje...  \n3                 1912  detecting condition effect on each individual\\...  \n4                 1912  While global inference is widely\\nused, local ...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>title</th>\n      <th>abstract</th>\n      <th>abstract_word_count</th>\n      <th>abstract_char_count</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>Reconstructing Subject-Specific Effect Maps</td>\n      <td>Predictive models allow subject-specific inf...</td>\n      <td>265</td>\n      <td>1912</td>\n      <td>Predictive models allow subject-specific inf...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>Reconstructing Subject-Specific Effect Maps</td>\n      <td>Predictive models allow subject-specific inf...</td>\n      <td>265</td>\n      <td>1912</td>\n      <td>Given a subject's data, inference can\\nbe made...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>Reconstructing Subject-Specific Effect Maps</td>\n      <td>Predictive models allow subject-specific inf...</td>\n      <td>265</td>\n      <td>1912</td>\n      <td>identifiying condition presence for the\\nsubje...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>Reconstructing Subject-Specific Effect Maps</td>\n      <td>Predictive models allow subject-specific inf...</td>\n      <td>265</td>\n      <td>1912</td>\n      <td>detecting condition effect on each individual\\...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>Reconstructing Subject-Specific Effect Maps</td>\n      <td>Predictive models allow subject-specific inf...</td>\n      <td>265</td>\n      <td>1912</td>\n      <td>While global inference is widely\\nused, local ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "23.471694129180648"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['word_count'] = df_train['text'].apply(lambda x: len(x.split()))\n",
    "df_train['word_count'].mean()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "158.59453263451604"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['char_count'] = df_train['text'].apply(lambda x: len(str(x)))\n",
    "df_train['char_count'].mean()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "df_train = df_train[df_train['word_count'] > 5]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# Cleaning\n",
    "def cleaning(s):\n",
    "  # Lowercase text\n",
    "  s = s.lower()\n",
    "  # Trim text\n",
    "  s = s.strip()\n",
    "  # Remove punctuations, special characters, URLs & hashtags\n",
    "  s = re.compile('<.*?>').sub('', s)\n",
    "  s = re.compile('[%s]' % re.escape(string.punctuation)).sub(' ', s)\n",
    "  s = re.sub('\\s+', ' ', s)\n",
    "  s = re.sub(r'\\[[0-9]*\\]', ' ', s)\n",
    "  s = re.sub(r'[^\\w\\s]', '', str(s).lower().strip())\n",
    "  s = re.sub(r'\\d', ' ', s)\n",
    "  s = re.sub(r'\\s+', ' ', s)\n",
    "\n",
    "  return s\n",
    "\n",
    "# Remove stopword\n",
    "def stopword(s):\n",
    "  a = [i for i in s.split() if i not in stopwords.words('english')]\n",
    "  return ' '.join(a)\n",
    "\n",
    "#LEMMATIZATION\n",
    "# Initialize the lemmatizer\n",
    "wl = WordNetLemmatizer()\n",
    "\n",
    "# This is a helper function to map NTLK position tags\n",
    "def get_wordnet_pos(tag):\n",
    "  if tag.startswith('J'):\n",
    "    return wordnet.ADJ\n",
    "  elif tag.startswith('V'):\n",
    "    return wordnet.VERB\n",
    "  elif tag.startswith('N'):\n",
    "    return wordnet.NOUN\n",
    "  elif tag.startswith('R'):\n",
    "    return wordnet.ADV\n",
    "  else:\n",
    "    return wordnet.NOUN\n",
    "\n",
    "# Tokenize the sentence\n",
    "def lemmatizer(s):\n",
    "  word_pos_tags = nltk.pos_tag(word_tokenize(s)) # Get position tags\n",
    "  a = [wl.lemmatize(tag[0], get_wordnet_pos(tag[1])) for idx, tag in enumerate(word_pos_tags)] # Map the position tag and lemmatize the word/token\n",
    "  return \" \".join(a)\n",
    "\n",
    "# Preprocessing\n",
    "def preprocess(s):\n",
    "  s = cleaning(s)\n",
    "  s = stopword(s)\n",
    "  s = lemmatizer(s)\n",
    "  return s"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 131034/131034 [08:42<00:00, 250.96it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": "   id                                        title  \\\n0   1  Reconstructing Subject-Specific Effect Maps   \n1   1  Reconstructing Subject-Specific Effect Maps   \n2   1  Reconstructing Subject-Specific Effect Maps   \n3   1  Reconstructing Subject-Specific Effect Maps   \n4   1  Reconstructing Subject-Specific Effect Maps   \n\n                                            abstract  abstract_word_count  \\\n0    Predictive models allow subject-specific inf...                  265   \n1    Predictive models allow subject-specific inf...                  265   \n2    Predictive models allow subject-specific inf...                  265   \n3    Predictive models allow subject-specific inf...                  265   \n4    Predictive models allow subject-specific inf...                  265   \n\n   abstract_char_count                                               text  \\\n0                 1912    Predictive models allow subject-specific inf...   \n1                 1912  Given a subject's data, inference can\\nbe made...   \n2                 1912  identifiying condition presence for the\\nsubje...   \n3                 1912  detecting condition effect on each individual\\...   \n4                 1912  While global inference is widely\\nused, local ...   \n\n   word_count  char_count                                         clean_text  \n0          13         117  predictive model allow subject specific infere...  \n1          13          73  give subject data inference make two level glo...  \n2           9          64    identifiying condition presence subject local e  \n3          12          92  detect condition effect individual measurement...  \n4          32         219  global inference widely use local inference us...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>title</th>\n      <th>abstract</th>\n      <th>abstract_word_count</th>\n      <th>abstract_char_count</th>\n      <th>text</th>\n      <th>word_count</th>\n      <th>char_count</th>\n      <th>clean_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>Reconstructing Subject-Specific Effect Maps</td>\n      <td>Predictive models allow subject-specific inf...</td>\n      <td>265</td>\n      <td>1912</td>\n      <td>Predictive models allow subject-specific inf...</td>\n      <td>13</td>\n      <td>117</td>\n      <td>predictive model allow subject specific infere...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>Reconstructing Subject-Specific Effect Maps</td>\n      <td>Predictive models allow subject-specific inf...</td>\n      <td>265</td>\n      <td>1912</td>\n      <td>Given a subject's data, inference can\\nbe made...</td>\n      <td>13</td>\n      <td>73</td>\n      <td>give subject data inference make two level glo...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>Reconstructing Subject-Specific Effect Maps</td>\n      <td>Predictive models allow subject-specific inf...</td>\n      <td>265</td>\n      <td>1912</td>\n      <td>identifiying condition presence for the\\nsubje...</td>\n      <td>9</td>\n      <td>64</td>\n      <td>identifiying condition presence subject local e</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>Reconstructing Subject-Specific Effect Maps</td>\n      <td>Predictive models allow subject-specific inf...</td>\n      <td>265</td>\n      <td>1912</td>\n      <td>detecting condition effect on each individual\\...</td>\n      <td>12</td>\n      <td>92</td>\n      <td>detect condition effect individual measurement...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>Reconstructing Subject-Specific Effect Maps</td>\n      <td>Predictive models allow subject-specific inf...</td>\n      <td>265</td>\n      <td>1912</td>\n      <td>While global inference is widely\\nused, local ...</td>\n      <td>32</td>\n      <td>219</td>\n      <td>global inference widely use local inference us...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['clean_text'] = df_train['text'].progress_apply(lambda x: preprocess(x))\n",
    "df_train.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "df_train[['id', 'title', 'text', 'clean_text']].to_csv('outputs/data.csv', index=False)"
   ],
   "metadata": {
    "id": "ErFV59NJQqhU",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 14,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "   id                                        title  \\\n0   1  Reconstructing Subject-Specific Effect Maps   \n1   1  Reconstructing Subject-Specific Effect Maps   \n2   1  Reconstructing Subject-Specific Effect Maps   \n3   1  Reconstructing Subject-Specific Effect Maps   \n4   1  Reconstructing Subject-Specific Effect Maps   \n\n                                                text  \\\n0    Predictive models allow subject-specific inf...   \n1  Given a subject's data, inference can\\nbe made...   \n2  identifiying condition presence for the\\nsubje...   \n3  detecting condition effect on each individual\\...   \n4  While global inference is widely\\nused, local ...   \n\n                                          clean_text  \n0  predictive model allow subject specific infere...  \n1  give subject data inference make two level glo...  \n2    identifiying condition presence subject local e  \n3  detect condition effect individual measurement...  \n4  global inference widely use local inference us...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>title</th>\n      <th>text</th>\n      <th>clean_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>Reconstructing Subject-Specific Effect Maps</td>\n      <td>Predictive models allow subject-specific inf...</td>\n      <td>predictive model allow subject specific infere...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>Reconstructing Subject-Specific Effect Maps</td>\n      <td>Given a subject's data, inference can\\nbe made...</td>\n      <td>give subject data inference make two level glo...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>Reconstructing Subject-Specific Effect Maps</td>\n      <td>identifiying condition presence for the\\nsubje...</td>\n      <td>identifiying condition presence subject local e</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>Reconstructing Subject-Specific Effect Maps</td>\n      <td>detecting condition effect on each individual\\...</td>\n      <td>detect condition effect individual measurement...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>Reconstructing Subject-Specific Effect Maps</td>\n      <td>While global inference is widely\\nused, local ...</td>\n      <td>global inference widely use local inference us...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv('outputs/data.csv')\n",
    "df_train.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Feature Extraction"
   ],
   "metadata": {
    "id": "lejYtB9n0T1h",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "wv = api.load('word2vec-google-news-300')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "index2word_set = set(wv.index_to_key)\n",
    "\n",
    "def avg_feature_vector(sentence, model, num_features, index):\n",
    "  words = sentence.split()\n",
    "  feature_vec = np.zeros((num_features, ), dtype='float32')\n",
    "  n_words = 0\n",
    "  for word in words:\n",
    "    if word in index:\n",
    "      n_words += 1\n",
    "      feature_vec = np.add(feature_vec, model[word])\n",
    "  if n_words > 0:\n",
    "    feature_vec = np.divide(feature_vec, n_words)\n",
    "  return feature_vec"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 131034/131034 [00:04<00:00, 29908.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.2636920722395563 0.2584988769652656\n"
     ]
    }
   ],
   "source": [
    "vectors = []\n",
    "for text in tqdm(df_train['clean_text']):\n",
    "  vec = avg_feature_vector(text, model=wv, num_features=300, index=index2word_set)\n",
    "  vectors.append(vec)\n",
    "\n",
    "scaler = Pipeline(steps=[\n",
    "  ('std', StandardScaler()),\n",
    "  ('minmax', MinMaxScaler((-1, 1)))\n",
    "])\n",
    "\n",
    "vectors = scaler.fit_transform(vectors)\n",
    "vectors = np.array([vector / np.linalg.norm(vector) for vector in vectors])\n",
    "print(np.min(vectors), np.max(vectors))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "# Export vectors\n",
    "np.save('outputs/vectors.npy', vectors)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "['models/scaler.joblib']"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Export scaler\n",
    "dump(scaler, 'models/scaler.joblib')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Export data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "connections.connect(\n",
    "  alias=\"default\",\n",
    "  host='localhost',\n",
    "  port='19530'\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "document_id = FieldSchema(\n",
    "  name=\"id\",\n",
    "  dtype=DataType.INT64,\n",
    "  is_primary=True,\n",
    "  auto_id=True\n",
    ")\n",
    "document_vector = FieldSchema(\n",
    "  name=\"vector\",\n",
    "  dtype=DataType.FLOAT_VECTOR,\n",
    "  dim=300\n",
    ")\n",
    "document_title = FieldSchema(\n",
    "  name=\"title\",\n",
    "  dtype=DataType.VARCHAR,\n",
    "  max_length=2048,\n",
    ")\n",
    "document_text = FieldSchema(\n",
    "  name=\"text\",\n",
    "  dtype=DataType.VARCHAR,\n",
    "  max_length=2048,\n",
    ")\n",
    "document_hash = FieldSchema(\n",
    "  name=\"hash\",\n",
    "  dtype=DataType.INT64,\n",
    ")\n",
    "schema = CollectionSchema(\n",
    "  fields=[document_id, document_vector, document_title, document_text, document_hash],\n",
    "  description=\"All Documents\",\n",
    ")\n",
    "\n",
    "collection_name = \"documents\"\n",
    "collection = Collection(\n",
    "  name=collection_name,\n",
    "  schema=schema,\n",
    "  using='default',\n",
    "  shards_num=2,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [00:12<00:00,  1.08it/s]\n"
     ]
    }
   ],
   "source": [
    "step = 10 ** 4\n",
    "for start in tqdm(range(0, vectors.shape[0], step)):\n",
    "  end = start + step\n",
    "  data = [\n",
    "    vectors[start:end].tolist(),\n",
    "    df_train['title'][start:end].str.strip().tolist(),\n",
    "    df_train['text'][start:end].str.strip().tolist(),\n",
    "    df_train['id'][start:end].astype(np.int64).tolist(),\n",
    "  ]\n",
    "  mr = collection.insert(data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "index_params = {\n",
    "  \"index_type\": \"IVF_FLAT\",\n",
    "  \"metric_type\": \"IP\",\n",
    "  \"params\": {\n",
    "    \"nlist\": 1024\n",
    "  }\n",
    "}\n",
    "\n",
    "collection.create_index(\n",
    "  field_name=\"vector\",\n",
    "  index_params=index_params,\n",
    "  index_name=\"vector_index\"\n",
    ")\n",
    "collection.load()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "colab": {
   "provenance": [],
   "collapsed_sections": [
    "3YQTEDJ-4O3w",
    "vYqHYtT80G6X"
   ],
   "toc_visible": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}